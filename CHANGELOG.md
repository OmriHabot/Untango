# Changelog

## v1.2.0 - Absolute Scoring Thresholds âš–ï¸

### ğŸ¯ New Feature: Quality-Based Result Filtering

**Absolute Scoring Thresholds**
- âœ… Vector similarity threshold filtering (0.0-1.0 range)
- âœ… BM25 score threshold filtering (0.0+ range)
- âœ… Pre-RRF filtering to prevent irrelevant results
- âœ… Prevents "best of the worst" ranking problem
- âœ… Optional per-query configuration

**How It Works**
1. Documents are scored by both vector and BM25 methods
2. Documents below absolute thresholds are filtered out **before** RRF fusion
3. Only high-quality documents participate in final ranking
4. Empty results signal no relevant documents found (better than misleading results)

**API Changes**
- Enhanced `/query` endpoint with `vector_similarity_threshold` parameter
- Enhanced `/query-hybrid` endpoint with both vector and BM25 thresholds
- Enhanced `/query-db` (RAG) endpoint with threshold support
- All threshold parameters are optional (backwards compatible)

**New Request Fields**
```json
{
  "query": "authentication system",
  "n_results": 10,
  "vector_similarity_threshold": 0.5,  // Optional: 0.0-1.0
  "bm25_score_threshold": 5.0          // Optional: 0.0+
}
```

**New Response Fields**
Hybrid search results now include raw scores for debugging:
- `similarity`: Raw vector similarity score (0.0-1.0)
- `bm25_score`: Raw BM25 relevance score
- `distance`: Vector distance (1 - similarity)

**Enhanced Search Functions**
- `perform_vector_search()`: Added similarity threshold filtering
- `perform_hybrid_search()`: Added dual threshold filtering with logging
- `distance_to_similarity()`: New helper for distance-to-similarity conversion

**Documentation**
- ğŸ“„ New: `THRESHOLD_FILTERING.md` - Comprehensive threshold guide
- ğŸ“„ Updated: `SEARCH_COMPARISON_GUIDE.md` - Threshold testing instructions
- ğŸ“„ Updated: `compare_search_endpoints.py` - Threshold support added

**Logging Improvements**
- Threshold filtering statistics logged at INFO level
- Shows how many results passed each threshold
- Warns when no results pass thresholds

**Configuration Guidelines**
- Vector: 0.5-0.7 recommended for moderate filtering
- BM25: 3.0-10.0 recommended for moderate filtering
- Start conservative, adjust based on results
- Different thresholds for different query types

**Use Cases**
- âœ… Large, diverse codebases (prevent irrelevant results)
- âœ… High-precision requirements (only relevant results)
- âœ… RAG pipelines (better context quality)
- âœ… Production systems (consistent quality)

**Benefits**
- Higher precision (more relevant results)
- Clear signal when no relevant results exist
- Better RAG answer quality
- Reduced noise in search results

### ğŸ”§ Technical Details

**Threshold Filtering Architecture**
```
Query â†’ Vector Search â†’ Threshold Filter â”€â”
                                           â”œâ”€â†’ RRF Fusion â†’ Results
Query â†’ BM25 Search â†’ Threshold Filter â”€â”€â”€â”˜
```

**Score Conversion**
- Cosine distance â†’ similarity: `1 - distance`
- L2 distance â†’ similarity: `1 / (1 + distance)`
- Inner product: Already a similarity score

**Backwards Compatibility**
- âœ… All threshold parameters are optional
- âœ… Default behavior unchanged (no filtering)
- âœ… Existing API calls continue to work

### ğŸ“Š Testing & Comparison

**Updated Comparison Script**
- Configurable thresholds at script level
- Shows raw scores in output (when available)
- Threshold status displayed in summary
- Easy A/B testing (with vs. without thresholds)

**Example Threshold Configuration**
```python
# In compare_search_endpoints.py
VECTOR_SIMILARITY_THRESHOLD = 0.5
BM25_SCORE_THRESHOLD = 5.0
```

---

## v1.1.0 - Complete RAG Pipeline

### ğŸ‰ New Feature: End-to-End RAG Platform

**New Endpoint: `/query-db`**
- âœ… Complete RAG pipeline combining retrieval + generation
- âœ… Hybrid search (vector + BM25) for intelligent chunk retrieval
- âœ… Confidence-based filtering (default threshold: 0.2)
- âœ… Context-aware prompt construction
- âœ… GCP Vertex AI integration for answer generation
- âœ… Comprehensive response with chunks, scores, and token usage

**New Models Added**
- `RAGQueryRequest` - Complete RAG query with configurable parameters
- `RAGQueryResponse` - Detailed response with answer and retrieved chunks
- `RetrievedChunk` - Chunk metadata with vector, BM25, and combined scores

**Usage Example**
```bash
curl -X POST "http://localhost:8001/query-db" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "How does authentication work?",
    "n_results": 10,
    "confidence_threshold": 0.2,
    "model": "gemini-2.0-flash-exp"
  }'
```

**Response includes:**
- AI-generated answer based on retrieved context
- All chunks used (with vector, BM25, combined scores)
- Token usage and estimated cost
- Metadata for each chunk (file, type, location)

**Test Suite Added**
- `test_rag_pipeline.py` - Comprehensive test script
- Tests: health â†’ ingest â†’ hybrid search â†’ RAG query
- Demonstrates complete end-to-end workflow

### ğŸ“š Documentation Updates
- README updated with `/query-db` endpoint documentation
- Usage examples for complete RAG workflow
- Response structure documented

---

## v1.0.0 - Production Ready Release

### ğŸ‰ Major Changes

**Codebase Cleanup**
- Removed 5 extra documentation files (consolidated into README)
- Removed 2 example/test files (functionality moved to API)
- Deleted `gcp_utils.py` (functionality inlined)
- Streamlined project structure

**Production-Ready API**
- âœ… Added proper Pydantic request/response models
- âœ… Type-safe endpoints with validation
- âœ… Renamed `/test-inference` â†’ `/inference` (proper endpoint naming)
- âœ… Request body validation (no URL parameters for complex data)
- âœ… Comprehensive error handling
- âœ… API documentation with FastAPI auto-docs

**New Models Added**
- `InferenceRequest` - Validated inference requests
- `InferenceResponse` - Structured inference responses  
- `TokenUsage` - Token usage tracking
- `HealthResponse` - Health check responses
- `SearchResult` - Search result structure

**Updated Endpoints**
- `POST /inference` - Production-ready AI inference (was `/test-inference`)
- `GET /health` - Returns structured `HealthResponse`
- All endpoints now have proper type hints and validation

**Improved README**
- Concise, production-focused documentation
- Quick start guide
- Clear API endpoint table
- Usage examples with curl
- Troubleshooting section
- Security best practices

### ğŸ“¦ Current Structure

```
Untango/
â”œâ”€â”€ app/                        # Clean, organized app structure
â”‚   â”œâ”€â”€ __init__.py            # Package init
â”‚   â”œâ”€â”€ main.py                # FastAPI app (229 lines)
â”‚   â”œâ”€â”€ models.py              # Pydantic models (68 lines)
â”‚   â”œâ”€â”€ database.py            # ChromaDB client (100 lines)
â”‚   â”œâ”€â”€ chunker.py             # Code chunking (122 lines)
â”‚   â””â”€â”€ search.py              # Hybrid search (108 lines)
â”œâ”€â”€ docker-compose.yaml         # Docker configuration
â”œâ”€â”€ Dockerfile                  # Container build
â”œâ”€â”€ README.md                   # Main documentation
â”œâ”€â”€ requirements.txt            # Python dependencies
â””â”€â”€ service-account-key.json   # GCP credentials (gitignored)
```

### ğŸ—‘ï¸ Removed Files

- `GCP_SETUP.md` (info moved to README)
- `QUICK_START_GCP.md` (consolidated)
- `RUN_TEST_INFERENCE.md` (consolidated)
- `example_vertex_ai.py` (use `/inference` endpoint)
- `test_inference.py` (use `/inference` endpoint)
- `app/gcp_utils.py` (inlined into main.py)

### ğŸ”’ Security

- All credentials in gitignore
- Read-only volume mounts in Docker
- No hardcoded secrets
- Type-safe validation prevents injection

### âœ… Quality Checks

- âœ… No linter errors
- âœ… All imports working
- âœ… Type hints validated
- âœ… Production-ready error handling
- âœ… Comprehensive API documentation

### ğŸ“š Documentation

Single source of truth: `README.md`
- API endpoints table
- Quick start guide
- Configuration reference
- Usage examples
- Troubleshooting

### ğŸš€ Usage

**Start services:**
```bash
docker-compose up --build -d
```

**Test inference:**
```bash
curl -X POST "http://localhost:8001/inference" \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Hello", "model": "gemini-2.0-flash-exp"}'
```

**Interactive docs:**
http://localhost:8001/docs

